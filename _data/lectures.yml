- date: 1
  title: >
    <strong>Introduction</strong>
  slides:
  topics:
    - What is Multimodal? Definitions, dimensions of heterogeneity and cross-modal interactions.<br/>
    - Historical view and multimodal research tasks.<br/>
    - Core technical challenges&#58; representation, alignment, transference, reasoning, generation, and quantification.<br/>
  readings:
    - <a href="https://arxiv.org/abs/2209.03430">Foundations and Trends in Multimodal Machine Learning&#58; Principles, Challenges, and Open Questions</a> <br/>

- date: 2
  title: >
    <strong>Multimodal challenges</strong>
  topics:
    - Why is multimodal hard? Introduction to core challenges. <br />
    - Overview of multimodal representation, alignment, reasoning, transfer, generation, and quantification. <br />
    - Identifying recent solutions for practitioners.
  readings:
    - <a href="https://www.sciencedirect.com/science/article/pii/S0167865513002584">Multimodal interaction&#58;A review </a> <br />
    - <a href="https://aclanthology.org/2020.emnlp-main.62/">Does my multimodal model learn cross-modal interactions? Itâ€™s harder to tell than you might think!</a> <br />
    - <a href="https://arxiv.org/abs/2405.07987">The Platonic Representation Hypothesis  </a> <br />
    
- date: 3
  title: >
    <strong>Recent advances in multimodal AI</strong>
  topics:
    - Multimodal transformers and foundation models <br />
    - Multimodal generative models <br />
    - Multimodal agents
  readings:
    - <a href="https://arxiv.org/abs/2303.16199">LLaMA-Adapter&#58; Efficient Fine-tuning of Language Models with Zero-init Attention</a> <br />
    - <a href="https://arxiv.org/abs/2301.03728">Scaling Laws for Generative Mixed-Modal Models </a> <br />
    - <a href="https://arxiv.org/abs/2309.05519">NExT-GPT&#58; Any-to-Any Multimodal LLM</a> <br />
  
- date: 4
  title: >
    <strong>Multimodal AI for Human Sensing </strong>
  topics:
    - Sensor data synthesis&#58; Video to Doppler, Video to IMU, Video to Audio, MoCap to IMU, MoCap to UWB <br />
    - Data augmentation <br />
    - Temporal data modeling 
  readings:
    - <a href="https://spice-lab.org/projects/Vid2Doppler/">Synthesizing Doppler Radar data for Privacy-Aware Activity Recognition</a> <br />
    - <a href="https://spice-lab.org/projects/MobilePoser/">MobilePoser&#58; Real-Time Full-Body Pose Estimation and 3D Human Translation from IMUs in Mobile Consumer Devices</a> <br />    

- date: 5
  title: >
    <strong>Ethics, interpretability and privacy</strong>
  topics:
    - Privacy and fairness concerns <br />
    - Handling errors and uncertainty <br />
    - Bringing humans into the loop <br />
  readings:
    - <a href="https://spice-lab.org/projects/SAMoSA/">SAMoSA&#58; Sensing Activities with Motion and Subsampled Audio</a> <br />

- date: 6
  title: >
    <strong>Applications</strong>
  topics:
    - Human activity recognition, pose estimation, gesture recognition <br />
    - Infrastructure and environmental sensing <br />
    - Wellness and fitness tracking, mobile health monitoring <br />
  readings:
    - <a href="https://chrisharrison.net/index.php/Research/DirectionOfVoice">Direction-of-Voice (DoV) Estimation for Intuitive Speech Interaction with Smart Devices Ecosystems</a> <br />
    - <a href="https://www.edusense.io/">EduSense&#58; Practical Classroom Sensing at Scale</a> <br />
    
- date: 7
  title: >
    <strong>Hardware and Sensors for Multimodal AI </strong>
  topics:
    - Challenges and opportunities in hardware and sensors for multimodal AI <br />
    - Importance of scalable, customizable hardware platforms <br />
    - Key applications benefiting from advancements in multimodal sensing and feedback interfaces
  readings:
    - <a href="https://stag.csail.mit.edu/">Learning the signatures of the human grasp using a scalable tactile glove</a> <br />
    
- date: 8
  title: >
    <strong>Multimodal sensing and feedback interface </strong>
  topics:
    - Advanced fabrication techniques for multimodal sensing hardware <br />
    - Addressing scalability, adaptability, and customization in hardware development <br />
    - Innovations in state-of-the-art data acquisition systems for multimodal interfaces <br />
    - Integration of diverse sensing modalities into compact, flexible form factors <br />
  readings:
    - <a href="https://adaptouch.csail.mit.edu/">Adaptive Tactile Interaction Transfer via Digitally Embroidered Smart Gloves</a> <br />
    - <a href="https://www.nature.com/articles/s41586-019-1687-0">Skin-integrated wireless haptic interfaces for virtual and augmented reality</a> <br />

- date: 9
  title: >
    <strong>Multisensory data fusion </strong>
  topics:
    - Approaches to synchronize and interpret multimodal data <br />
    - Strategies for enhancing signal quality and accuracy <br />
    - Future directions enabled by multisensory interfaces <br />
  readings:
    - <a href="https://action-sense.csail.mit.edu/">ActionSense&#58; A Multimodal Dataset and Recording Framework for Human Activities Using Wearable Sensors in a Kitchen Environment</a> <br />
    - <a href="https://binghao-huang.github.io/3D-ViTac/">3D-ViTac Learning Fine-Grained Manipulation with Visuo-Tactile Sensing</a> <br />

